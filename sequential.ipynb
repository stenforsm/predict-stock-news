{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequential.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMW8BCXCsJ3IjzxcVRI79Yn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stenforsm/predict-stock-news/blob/main/sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbiileZcSX4o"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05bn-BwjSgNa"
      },
      "source": [
        "df = pd.read_csv('b_news.csv') # choose which company file to work with here\n",
        "x = df.title.values # process full headline\n",
        "price = df[\"close price change\"].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u6XENhUSkUF"
      },
      "source": [
        "# class_plus = 1; class_minus = 0\n",
        "y = np.sign(price) # labels extracted by checking if +ve or -ve\n",
        "y = np.where(y==1,1,0)\n",
        "weight = np.abs(price) # sample weight is absolute price change value"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcHwSNuwSoz5"
      },
      "source": [
        "# test train split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test, w_train, w_test = train_test_split(x, y, weight, test_size=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vy4szDXTLYT"
      },
      "source": [
        "# text vectorization\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')\n",
        "\n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (without labels), then call adapt\n",
        "vectorize_layer.adapt(x_train)\n",
        "\n",
        "def vectorize_text(text):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text)\n",
        "\n",
        "x_train = vectorize_text(x_train)\n",
        "x_test = vectorize_text(x_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOHMc0yQTVQQ",
        "outputId": "b6dcc646-1c1d-4a0d-c62c-b2006ed4f01c"
      },
      "source": [
        "embedding_dim = 16\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(1, activation='softmax')])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "class_weight = {0: 1.,\n",
        "                1: 50.} # this can be adjusted"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwqXfEGuTeYD",
        "outputId": "60695927-75dc-4361-e168-23a5e8d2d802"
      },
      "source": [
        "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
        "\n",
        "model.fit(x_train, y_train, class_weight=class_weight, sample_weight=w_train, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4994: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191/191 [==============================] - 1s 5ms/step - loss: 9.7994 - binary_accuracy: 0.3888\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 1s 4ms/step - loss: 3.4787 - binary_accuracy: 0.3888\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 1s 4ms/step - loss: 2.4020 - binary_accuracy: 0.3888\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 1s 4ms/step - loss: 2.2826 - binary_accuracy: 0.3888\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 1s 4ms/step - loss: 2.2685 - binary_accuracy: 0.3888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b534d1ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3xWqs2GT-qG",
        "outputId": "b3b3e453-161f-4eda-f390-30d091df72c0"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 0s 1ms/step - loss: 2.2829 - binary_accuracy: 0.3916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4994: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.282865047454834, 0.3916175365447998]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKHA61Y0UCT7",
        "outputId": "6f85de08-5ee0-4279-9725-e4430c60c502"
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "y_predict = np.argmax(predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "print(matthews_corrcoef(y_test, y_predict))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[929   0]\n",
            " [598   0]]\n",
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        }
      ]
    }
  ]
}